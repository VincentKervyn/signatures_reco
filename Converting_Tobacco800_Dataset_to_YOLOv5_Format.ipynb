{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer [this blog](https://towardsai.net/p/computer-vision/yolo-v5-object-detection-on-a-custom-dataset) for more information. Its an excellent resource.  \n",
    "Tobacco 800 dataset could be downloaded from [here](http://tc11.cvc.uab.es/datasets/Tobacco800_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting information from Tobacco-800 XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "cnt = 0\n",
    "\n",
    "# refer the xml files to understand its structure and revist this code block.\n",
    "annotations = sorted(glob('data/train_xml/*.xml'))\n",
    "for file in annotations:\n",
    "    myroot = ET.parse(file).getroot()\n",
    "    # image filename is changed aah97e00-page02_1.tif -> 0.tif, so the previous filename is collected here.\n",
    "    prev_filename = myroot[0].attrib['src']\n",
    "    filename = str(cnt) + '.tif' # new filename based on the count (0.tif, 1.tif etc)\n",
    "    page_height, page_width =  myroot[0][0].attrib['height'], myroot[0][0].attrib['width']\n",
    "    \n",
    "    row = []\n",
    "    # An image might have multiple items (zones) (logos and signs), so iterate through each zones\n",
    "    for zone in myroot[0][0]:\n",
    "        category = zone.attrib['gedi_type'] # type of zone (DLLogo/ DLSignature)\n",
    "        id = zone.attrib['id']\n",
    "        x, y = zone.attrib['col'], zone.attrib['row'] # x, y coordinate\n",
    "        w, h = zone.attrib['width'], zone.attrib['height'] # width and height of bbox\n",
    "        \n",
    "        # Signature have Authors, represeting whose signature it is\n",
    "        if category == 'DLSignature':\n",
    "            AuthorID = zone.attrib['AuthorID']\n",
    "            Overlapped = zone.attrib['Overlapped']\n",
    "        else:\n",
    "            # Logos don't have authors.\n",
    "            AuthorID, Overlapped = ('NA', 'NA')\n",
    "        row = [prev_filename, filename, page_height, page_width, AuthorID, Overlapped, category, id, x, y, w, h]\n",
    "        df.append(row)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the information to Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df, columns=['prev_filename', 'filename', 'page_height', 'page_width', 'AuthorID', 'Overlapped', 'category', 'id', 'x', 'y', 'width', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(page_height    NaN\n page_width     NaN\n dtype: object,\n page_height    NaN\n page_width     NaN\n dtype: object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data[['page_height', 'page_width']]\n",
    "test.max(), test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the image to reduce training time**  \n",
    "To save on training time, resize the images to a maximum height and width of 640 and 480. While resizing the image, the bounding box cordinates also changes. This code computes how much each image is shrinken and updates the bounding box coordinates appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tobacco_data_zhugy/scaled'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_136759/1826521929.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mBASE_DIR\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'tobacco_data_zhugy/pages/'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mSAVE_PATH\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'tobacco_data_zhugy/scaled'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmkdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSAVE_PATH\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mscale_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'tobacco_data_zhugy/scaled'"
     ]
    }
   ],
   "source": [
    "BASE_DIR = 'tobacco_data_zhugy/pages/'\n",
    "SAVE_PATH = 'tobacco_data_zhugy/scaled'\n",
    "os.mkdir(SAVE_PATH)\n",
    "\n",
    "def scale_image(df):\n",
    "    df_new = []\n",
    "    filename = df.prev_filename\n",
    "    X, Y, W, H = map(int, df.x), map(int, df.y), map(int, df.width), map(int, df.height)\n",
    "    for file, x, y, w, h in zip(filename, X, Y, W, H):\n",
    "        image_path = BASE_DIR + file\n",
    "        img = cv2.imread(image_path, 1)\n",
    "        page_height, page_width = img.shape[:2]\n",
    "        max_height = 640\n",
    "        max_width = 480\n",
    "        \n",
    "        # computes the scaling factor\n",
    "        if max_height < page_height or max_width < page_width:\n",
    "            scaling_factor = max_height / float(page_height)\n",
    "            if max_width/float(page_width) < scaling_factor:\n",
    "                scaling_factor = max_width / float(page_width)\n",
    "            # scale the image with the scaling factor\n",
    "            img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "        jpg_filename = file[:-4] + '.jpg'\n",
    "        new_file_path = SAVE_PATH + jpg_filename\n",
    "        cv2.imwrite(new_file_path, img) # write the scales image\n",
    "        \n",
    "        # save new page height and width\n",
    "        page_height, page_width = page_height*scaling_factor, page_width*scaling_factor\n",
    "        # compute new x, y, w, h coordinates after scaling\n",
    "        x, y, w, h= int(x*scaling_factor), int(y*scaling_factor), int(w*scaling_factor), int(h*scaling_factor)\n",
    "        row = [jpg_filename, x, y, w, h, page_height, page_width]\n",
    "        df_new.append(row)\n",
    "    return df_new\n",
    "scaled_data = scale_image(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding the information regarding the scaling to the df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = list(zip(*scaled_data))\n",
    "\n",
    "data['new_filename'] = scaled_data[0]\n",
    "data['x_scaled'] = scaled_data[1]\n",
    "data['y_scaled'] = scaled_data[2]\n",
    "data['w_scaled'] = scaled_data[3]\n",
    "data['h_scaled'] = scaled_data[4]\n",
    "data['page_height_scaled'] = scaled_data[5]\n",
    "data['page_width_scaled'] = scaled_data[6]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the scaled image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('tobacco_data_zhugy/scaled/agw39d00.jpg')\n",
    "\n",
    "img = cv2.rectangle(img, (90, 348), (90+120, 348+26), (255, 0, 0), 1)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving to CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['prev_filename', 'new_filename', 'filename', 'page_height', 'page_width', 'page_height_scaled', 'page_width_scaled', 'AuthorID', 'Overlapped', 'category', 'id', 'x', 'y', 'width', 'height', 'x_scaled', 'y_scaled', 'w_scaled', 'h_scaled']].to_csv('tobacco_data_zhugy/tobacco_cleaned.csv', index=False)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data to YOLOv5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_center(df):\n",
    "  return int(df.x_scaled + (df.w_scaled/2))\n",
    "def y_center(df):\n",
    "  return int(df.y_scaled + (df.h_scaled/2))\n",
    "\n",
    "def w_norm(df, col):\n",
    "  return df[col]/df['page_width_scaled']\n",
    "def h_norm(df, col):\n",
    "  return df[col]/df['page_height_scaled']\n",
    "\n",
    "df = pd.read_csv('tobacco_data_zhugy/tobacco_cleaned.csv')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['category'])\n",
    "print(le.classes_)\n",
    "labels = le.transform(df['category'])\n",
    "df['labels'] = labels\n",
    "\n",
    "\n",
    "df['x_center'] = df.apply(x_center, axis=1)\n",
    "df['y_center'] = df.apply(y_center, axis=1)\n",
    "\n",
    "df['x_center_norm'] = df.apply(w_norm, col='x_center',axis=1)\n",
    "df['width_norm'] = df.apply(w_norm, col='w_scaled', axis=1)\n",
    "\n",
    "df['y_center_norm'] = df.apply(h_norm, col='y_center',axis=1)\n",
    "df['height_norm'] = df.apply(h_norm, col='h_scaled',axis=1)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving images to train and valid folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = model_selection.train_test_split(df, test_size=0.1, random_state=13, shuffle=True)\n",
    "print(df_train.shape, df_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating relevant directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/')\n",
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/images/')\n",
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/images/train/')\n",
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/images/valid/')\n",
    "\n",
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/labels/')\n",
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/labels/train/')\n",
    "os.mkdir('tobacco_data_zhugy/tobacco_yolo_format/labels/valid/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segregating images and labels to train and valid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segregate_data(df, img_path, label_path, train_img_path, train_label_path):\n",
    "  filenames = []\n",
    "  for filename in df.filename:\n",
    "    filenames.append(filename)\n",
    "  filenames = set(filenames)\n",
    "  \n",
    "  for filename in filenames:\n",
    "    yolo_list = []\n",
    "\n",
    "    for _,row in df[df.filename == filename].iterrows():\n",
    "      yolo_list.append([row.labels, row.x_center_norm, row.y_center_norm, row.width_norm, row.height_norm])\n",
    "\n",
    "    yolo_list = np.array(yolo_list)\n",
    "    txt_filename = os.path.join(train_label_path,str(row.new_filename.split('.')[0])+\".txt\")\n",
    "    # Save the .img & .txt files to the corresponding train and validation folders\n",
    "    np.savetxt(txt_filename, yolo_list, fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"])\n",
    "    shutil.copyfile(os.path.join(img_path,row.new_filename), os.path.join(train_img_path,row.new_filename))\n",
    " \n",
    "# Apply function\n",
    "src_img_path = \"tobacco_data_zhugy/scaled/\"\n",
    "src_label_path = \"tobacco_data_zhugy/groundtruth/\"\n",
    "\n",
    "train_img_path = \"tobacco_data_zhugy/tobacco_yolo_format/images/train\"\n",
    "train_label_path = \"tobacco_data_zhugy/tobacco_yolo_format/labels/train\"\n",
    "\n",
    "valid_img_path = \"tobacco_data_zhugy/tobacco_yolo_format/images/valid\"\n",
    "valid_label_path = \"tobacco_data_zhugy/tobacco_yolo_format/labels/valid\"\n",
    "\n",
    "segregate_data(df_train, src_img_path, src_label_path, train_img_path, train_label_path)\n",
    "segregate_data(df_valid, src_img_path, src_label_path, valid_img_path, valid_label_path)\n",
    "\n",
    "print(\"No. of Training images\", len(os.listdir('tobacco_data_zhugy/tobacco_yolo_format/images/train')))\n",
    "print(\"No. of Training labels\", len(os.listdir('tobacco_data_zhugy/tobacco_yolo_format/labels/train')))\n",
    "\n",
    "print(\"No. of valid images\", len(os.listdir('tobacco_data_zhugy/tobacco_yolo_format/images/valid')))\n",
    "print(\"No. of valid labels\", len(os.listdir('tobacco_data_zhugy/tobacco_yolo_format/labels/valid')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deleting ipython checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  shutil.rmtree('tobacco_data_zhugy/tobacco_yolo_format/images/train/.ipynb_checkpoints')\n",
    "except FileNotFoundError:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  shutil.rmtree('tobacco_data_zhugy/tobacco_yolo_format/images/valid/.ipynb_checkpoints')\n",
    "except FileNotFoundError:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  shutil.rmtree('tobacco_data_zhugy/tobacco_yolo_format/labels/train/.ipynb_checkpoints')\n",
    "except FileNotFoundError:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  shutil.rmtree('tobacco_data_zhugy/tobacco_yolo_format/labels/valid/.ipynb_checkpoints')\n",
    "except FileNotFoundError:\n",
    "  pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}